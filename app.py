import streamlit as st
import os
import PyPDF2
from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv()

# Page configuration
st.set_page_config(
    page_title="PDF ë¶„ì„ ë° Q&A ì‹œìŠ¤í…œ",
    page_icon="ğŸ“„",
    layout="wide"
)

# Initialize API Client
def get_client():
    api_key = os.getenv("GROQ_API_KEY")
    # Also check Streamlit secrets for deployment
    if not api_key and "GROQ_API_KEY" in st.secrets:
        api_key = st.secrets["GROQ_API_KEY"]
    
    if api_key:
        return OpenAI(
            base_url="https://api.groq.com/openai/v1",
            api_key=api_key
        )
    return None

client = get_client()
MODEL_NAME = "openai/gpt-oss-120b"

def extract_text_from_pdf(file):
    text = ""
    try:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            extracted = page.extract_text()
            if extracted:
                text += extracted + "\n"
    except Exception as e:
        st.error(f"Error reading PDF: {e}")
        return None
    return text

def analyze_report(text):
    if not client:
        st.warning("API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì´ë‚˜ Streamlit Secretsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None

    try:
        # Truncate text for context window
        truncated_text = text[:15000]
        
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ ë³´ê³ ì„œ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µë˜ëŠ” [ë³´ê³ ì„œ ì „ì²´ í…ìŠ¤íŠ¸]ë¥¼ ì½ê³  ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:
        1. ì´ ë³´ê³ ì„œì˜ í•µì‹¬ ì£¼ì œì™€ ëª©ì ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
        2. ì „ì²´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 5ê°œì˜ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
        3. ë³´ê³ ì„œì˜ ì „ì²´ì ì¸ ë…¼ì¡°ì™€ ê²°ë¡ ì„ ìš”ì•½í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•  ì¤€ë¹„ë¥¼ í•˜ì„¸ìš”.
        
        [ë³´ê³ ì„œ ì „ì²´ í…ìŠ¤íŠ¸]
        {truncated_text}
        
        ì‘ë‹µ í˜•ì‹(JSON):
        {{
            "summary": "ìš”ì•½ ë‚´ìš©",
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", "í‚¤ì›Œë“œ4", "í‚¤ì›Œë“œ5"]
        }}
        """
        
        completion = client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        
        import json
        return json.loads(completion.choices[0].message.content)
    except Exception as e:
        st.error(f"Error during analysis: {e}")
        return None

def get_answer(question, context):
    if not client:
        return "API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
    try:
        # Truncate context for Q&A
        cmd_context = context[:20000]
        
        prompt = f"""
        ì‚¬ìš©ìê°€ ë‹¤ìŒ ì§ˆë¬¸ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤: {question}.
        ì „ì²´ ë³´ê³ ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
        ë‹µë³€ ì‹œ ë°˜ë“œì‹œ ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”:
        1. ë³´ê³ ì„œ ë‚´ì— ê·¼ê±°ê°€ ìˆëŠ” ë‚´ìš©ë§Œ ë‹µë³€ì— í¬í•¨í•˜ì„¸ìš”.
        2. ë§Œì•½ ë³´ê³ ì„œì— ê´€ë ¨ ë‚´ìš©ì´ ì—†ë‹¤ë©´ 'ë³´ê³ ì„œ ë‚´ì—ì„œëŠ” í™•ì¸ë˜ì§€ ì•ŠëŠ” ë‚´ìš©ì…ë‹ˆë‹¤'ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.
        3. ë‹µë³€ì˜ ì‹ ë¢°ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ê´€ë ¨ ë‚´ìš©ì´ ìœ„ì¹˜í•œ ë³´ê³ ì„œì˜ ì„¹ì…˜ì´ë‚˜ í˜ì´ì§€ë¥¼ ì–¸ê¸‰í•˜ì„¸ìš”(ê°€ëŠ¥í•œ ê²½ìš°).
        
        [ë³´ê³ ì„œ ì „ì²´ í…ìŠ¤íŠ¸]
        {cmd_context}
        """
        
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}]
        )
        
        return completion.choices[0].message.content
    except Exception as e:
        return f"Error responding to question: {e}"

# UI Layout
st.title("ğŸ“„ PDF ë¶„ì„ ë° Q&A ì‹œìŠ¤í…œ")

with st.sidebar:
    st.header("ì„¤ì • ë° ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['pdf'])
    
    if not client:
        st.error("âš ï¸ Groq API Keyê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ë¡œì»¬ ì‹¤í–‰ ì‹œ .env íŒŒì¼ì— GROQ_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜, Streamlit Cloud ë°°í¬ ì‹œ Secretsì— ì¶”ê°€í•˜ì„¸ìš”.")

if uploaded_file is not None:
    # Process PDF
    if 'pdf_text' not in st.session_state or st.session_state.current_file != uploaded_file.name:
        with st.spinner("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
            text = extract_text_from_pdf(uploaded_file)
            if text:
                st.session_state.pdf_text = text
                st.session_state.current_file = uploaded_file.name
                # Reset analysis on new file
                if 'analysis_result' in st.session_state:
                    del st.session_state.analysis_result
                if 'messages' in st.session_state:
                    del st.session_state.messages
            else:
                st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if 'pdf_text' in st.session_state:
        # Create tabs
        tab1, tab2 = st.tabs(["ğŸ“Š ë¶„ì„ ê²°ê³¼", "ğŸ’¬ Q&A ì±„íŒ…"])
        
        with tab1:
            st.header("ë³´ê³ ì„œ ë¶„ì„")
            if st.button("ë³´ê³ ì„œ ë¶„ì„ ì‹œì‘"):
                with st.spinner("AIê°€ ë³´ê³ ì„œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    result = analyze_report(st.session_state.pdf_text)
                    if result:
                        st.session_state.analysis_result = result
            
            if 'analysis_result' in st.session_state:
                res = st.session_state.analysis_result
                st.subheader("ğŸ“ ìš”ì•½")
                st.info(res.get('summary', 'ìš”ì•½ ì—†ìŒ'))
                
                st.subheader("ğŸ”‘ ì£¼ìš” í‚¤ì›Œë“œ")
                # Display keywords as tags
                cols = st.columns(len(res.get('keywords', [])))
                for i, keyword in enumerate(res.get('keywords', [])):
                    # Use container or just write
                    st.success(f"#{keyword}")

        with tab2:
            st.header("ì§ˆë¬¸í•˜ê¸°")
            
            # Initialize chat history
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # Display chat messages from history on app rerun
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

            # React to user input
            if prompt := st.chat_input("ë³´ê³ ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”"):
                # Display user message in chat message container
                st.chat_message("user").markdown(prompt)
                # Add user message to chat history
                st.session_state.messages.append({"role": "user", "content": prompt})

                with st.chat_message("assistant"):
                    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                        response = get_answer(prompt, st.session_state.pdf_text)
                        st.markdown(response)
                
                # Add assistant response to chat history
                st.session_state.messages.append({"role": "assistant", "content": response})

else:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

